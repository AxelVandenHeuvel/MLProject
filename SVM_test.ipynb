{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T01:54:46.602335Z",
     "start_time": "2025-05-05T01:53:27.881546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class SVM(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SVM, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc3(x)\n",
    "\n",
    "class BasketballMomentumSVM:\n",
    "    def __init__(self, num_previous_plays=5, momentum_threshold=6, learning_rate=0.001,\n",
    "                 epochs=150, reg_param=0.01, batch_size=64, class_weight=10.0,\n",
    "                 verbose=True):\n",
    "        \"\"\"\n",
    "        Initialize the Basketball Momentum SVM model with PyTorch\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        num_previous_plays : int\n",
    "            Number of previous plays to consider for prediction\n",
    "        momentum_threshold : int\n",
    "            Number of consecutive points to define a momentum shift\n",
    "        learning_rate : float\n",
    "            Learning rate for optimizer\n",
    "        epochs : int\n",
    "            Number of training epochs\n",
    "        reg_param : float\n",
    "            Regularization parameter\n",
    "        batch_size : int\n",
    "            Batch size for training\n",
    "        class_weight : float\n",
    "            Weight for the positive class (momentum shift starts)\n",
    "        verbose : bool\n",
    "            Whether to print detailed debug information\n",
    "        \"\"\"\n",
    "        self.num_previous_plays = num_previous_plays\n",
    "        self.momentum_threshold = momentum_threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.reg_param = reg_param\n",
    "        self.batch_size = batch_size\n",
    "        self.class_weight = class_weight\n",
    "        self.scaler = StandardScaler()\n",
    "        self.input_dim = None\n",
    "        self.model = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _safe_numeric_convert(self, value, default=0.0):\n",
    "        \"\"\"Safely convert a value to float\"\"\"\n",
    "        try:\n",
    "            return float(value)\n",
    "        except (ValueError, TypeError):\n",
    "            return default\n",
    "\n",
    "    def preprocess_data(self, data):\n",
    "        \"\"\"\n",
    "        Preprocess the input data to ensure numeric types\n",
    "        \"\"\"\n",
    "        # Columns that should be numeric\n",
    "        numeric_columns = [\n",
    "            'play_id', 'half', 'time_remaining_half', 'secs_remaining',\n",
    "            'secs_remaining_absolute', 'home_score', 'away_score', 'score_diff',\n",
    "            'play_length', 'scoring_play', 'foul', 'win_prob', 'naive_win_prob',\n",
    "            'home_time_out_remaining', 'away_time_out_remaining', 'home_favored_by',\n",
    "            'total_line', 'attendance', 'three_pt', 'free_throw'\n",
    "        ]\n",
    "\n",
    "        # Create a copy to avoid modifying the original\n",
    "        processed_data = data.copy()\n",
    "\n",
    "        # Convert each column to numeric\n",
    "        for col in numeric_columns:\n",
    "            if col in processed_data.columns:\n",
    "                processed_data[col] = pd.to_numeric(processed_data[col], errors='coerce')\n",
    "                processed_data[col] = processed_data[col].fillna(0)\n",
    "\n",
    "        return processed_data\n",
    "\n",
    "    def find_momentum_shifts(self, df):\n",
    "        \"\"\"\n",
    "        Find momentum shifts using the user's exact algorithm\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : DataFrame\n",
    "            Full dataset with all plays\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        df : DataFrame\n",
    "            Updated dataframe with 'run_label' column\n",
    "        runs_df : DataFrame\n",
    "            DataFrame containing all identified runs\n",
    "        \"\"\"\n",
    "        # Sort data by game and play ID\n",
    "        df = df.sort_values(['game_id', 'play_id'], ascending=[True, True]).reset_index(drop=True)\n",
    "        runs = []\n",
    "\n",
    "        for game_id, game_df in df.groupby('game_id'):\n",
    "            home = game_df.iloc[0]['home']\n",
    "            away = game_df.iloc[0]['away']\n",
    "\n",
    "            # Track cumulative points scored\n",
    "            home_score = 0\n",
    "            away_score = 0\n",
    "\n",
    "            # Track potential runs\n",
    "            run_points = {home: 0, away: 0}\n",
    "            run_start_index = None\n",
    "            run_start_time = None\n",
    "\n",
    "            for idx, row in game_df.iterrows():\n",
    "                new_home_score = self._safe_numeric_convert(row['home_score'])\n",
    "                new_away_score = self._safe_numeric_convert(row['away_score'])\n",
    "\n",
    "                # Determine who scored (if anyone)\n",
    "                if new_home_score != home_score or new_away_score != away_score:\n",
    "                    # Someone scored\n",
    "                    scoring_team = home if new_home_score != home_score else away\n",
    "                    points_scored = (new_home_score - home_score) if scoring_team == home else (new_away_score - away_score)\n",
    "\n",
    "                    if run_points[scoring_team] == 0:\n",
    "                        # First points in the run\n",
    "                        run_start_index = idx\n",
    "                        run_start_time = row['time_remaining_half']\n",
    "\n",
    "                    run_points[scoring_team] += points_scored\n",
    "                    # Reset the opponent's run points if they score\n",
    "                    opponent = away if scoring_team == home else home\n",
    "                    run_points[opponent] = 0\n",
    "\n",
    "                    # Check if run is 6+ to 0\n",
    "                    if run_points[scoring_team] >= self.momentum_threshold and run_points[opponent] == 0:\n",
    "                        runs.append({\n",
    "                            'game_id': game_id,\n",
    "                            'team': scoring_team,\n",
    "                            'start_play_id': game_df.loc[run_start_index]['play_id'],\n",
    "                            'start_index': run_start_index,  # Store the DataFrame index too\n",
    "                            'start_time': run_start_time,\n",
    "                            'end_play_id': row['play_id'],\n",
    "                            'end_index': idx,  # Store the DataFrame index too\n",
    "                            'end_time': row['time_remaining_half'],\n",
    "                            'points_scored': run_points[scoring_team]\n",
    "                        })\n",
    "\n",
    "                        # After finding a run, reset\n",
    "                        run_points[scoring_team] = 0\n",
    "                        run_start_index = None\n",
    "                        run_start_time = None\n",
    "\n",
    "                home_score = new_home_score\n",
    "                away_score = new_away_score\n",
    "\n",
    "        # Turn the runs list into a DataFrame\n",
    "        runs_df = pd.DataFrame(runs)\n",
    "\n",
    "        # Add the run_label column to the original DataFrame if it doesn't exist\n",
    "        if 'run_label' not in df.columns:\n",
    "            df['run_label'] = 0\n",
    "\n",
    "        # Loop through each scoring run\n",
    "        for _, run in runs_df.iterrows():\n",
    "            game_id = run['game_id']\n",
    "            start_play_id = run['start_play_id']\n",
    "            end_play_id = run['end_play_id']\n",
    "\n",
    "            # Apply mask: match game_id and play_id in range\n",
    "            mask = (\n",
    "                (df['game_id'] == game_id) &\n",
    "                (df['play_id'] >= start_play_id) &\n",
    "                (df['play_id'] <= end_play_id)\n",
    "            )\n",
    "\n",
    "            # Apply the label\n",
    "            df.loc[mask, 'run_label'] = 1\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Found {len(runs_df)} momentum shifts (runs of {self.momentum_threshold}+ points)\")\n",
    "            print(f\"Total plays in runs: {df['run_label'].sum()}\")\n",
    "            print(f\"Percentage of plays in runs: {df['run_label'].mean()*100:.2f}%\")\n",
    "\n",
    "        return df, runs_df\n",
    "\n",
    "    def find_momentum_shift_starts(self, df, runs_df):\n",
    "        \"\"\"\n",
    "        Identify the starting plays of momentum shifts based on runs_df\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : DataFrame\n",
    "            Full dataset with all plays\n",
    "        runs_df : DataFrame\n",
    "            DataFrame containing all identified runs\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        df : DataFrame\n",
    "            Updated dataframe with 'momentum_start' column\n",
    "        \"\"\"\n",
    "        # Add the momentum_start column to the original DataFrame\n",
    "        df['momentum_start'] = 0\n",
    "\n",
    "        # Loop through each scoring run and mark only the starting play\n",
    "        for _, run in runs_df.iterrows():\n",
    "            game_id = run['game_id']\n",
    "            start_play_id = run['start_play_id']\n",
    "\n",
    "            # Apply mask: match game_id and exact start play_id\n",
    "            mask = (\n",
    "                (df['game_id'] == game_id) &\n",
    "                (df['play_id'] == start_play_id)\n",
    "            )\n",
    "\n",
    "            # Apply the label to the starting play only\n",
    "            df.loc[mask, 'momentum_start'] = 1\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Identified {df['momentum_start'].sum()} momentum shift starting plays\")\n",
    "            print(f\"Percentage of momentum shift starts: {df['momentum_start'].mean()*100:.2f}%\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def prepare_data(self, game_data):\n",
    "        \"\"\"Prepare the data for training/prediction\"\"\"\n",
    "        # First, preprocess the data\n",
    "        data = self.preprocess_data(game_data)\n",
    "\n",
    "        # Find momentum shifts\n",
    "        data, runs_df = self.find_momentum_shifts(data)\n",
    "\n",
    "        # Identify momentum shift starts\n",
    "        data = self.find_momentum_shift_starts(data, runs_df)\n",
    "\n",
    "        # Extract features from previous plays\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        # Keep track of which plays we're using for training/prediction\n",
    "        play_indices = []\n",
    "\n",
    "        # Iterate through each game in the dataset\n",
    "        for game_id in data['game_id'].unique():\n",
    "            game_plays = data[data['game_id'] == game_id].sort_values(by=['play_id']).reset_index(drop=True)\n",
    "\n",
    "            # Create sliding windows of plays\n",
    "            for i in range(self.num_previous_plays, len(game_plays)):\n",
    "                try:\n",
    "                    # Get previous plays as features\n",
    "                    prev_plays = game_plays.iloc[i-self.num_previous_plays:i]\n",
    "                    current_play = game_plays.iloc[i]\n",
    "\n",
    "                    # Extract relevant features from previous plays\n",
    "                    features = self._extract_features(prev_plays, current_play)\n",
    "\n",
    "                    # Check if this play starts a momentum shift\n",
    "                    is_momentum_start = current_play['momentum_start']\n",
    "\n",
    "                    X.append(features)\n",
    "                    y.append(is_momentum_start)\n",
    "\n",
    "                    # Store the original index of this play\n",
    "                    play_indices.append(current_play.name)\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Skip problematic plays but print error for debugging\n",
    "                    if self.verbose:\n",
    "                        print(f\"Error processing play in game {game_id}, index {i}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        X_np = np.array(X)\n",
    "        y_np = np.array(y)\n",
    "\n",
    "        if len(y_np) == 0:\n",
    "            raise ValueError(\"No valid plays were processed. Check your data.\")\n",
    "\n",
    "        print(f\"Total plays processed: {len(X_np)}\")\n",
    "        print(f\"Momentum shift starts detected: {sum(y_np)} out of {len(y_np)} plays ({sum(y_np)/len(y_np)*100:.2f}%)\")\n",
    "\n",
    "        # Print class distribution\n",
    "        print(\"Class distribution:\", Counter(y_np))\n",
    "\n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X_np)\n",
    "\n",
    "        # Set input dimension for the model\n",
    "        self.input_dim = X_scaled.shape[1]\n",
    "\n",
    "        # Convert to PyTorch tensors and move to GPU\n",
    "        X_tensor = torch.FloatTensor(X_scaled).to(device)\n",
    "        y_tensor = torch.FloatTensor(y_np).view(-1, 1).to(device)\n",
    "\n",
    "        return X_tensor, y_tensor, play_indices\n",
    "\n",
    "    def _extract_features(self, prev_plays, current_play):\n",
    "        \"\"\"Extract relevant features from a sequence of plays\"\"\"\n",
    "        features = []\n",
    "\n",
    "        # Home team and away team\n",
    "        home_team = current_play['home']\n",
    "        away_team = current_play['away']\n",
    "\n",
    "        # Game Context Features\n",
    "        # 1. Score differential and raw scores\n",
    "        score_diff = self._safe_numeric_convert(current_play['score_diff'])\n",
    "        home_score = self._safe_numeric_convert(current_play['home_score'])\n",
    "        away_score = self._safe_numeric_convert(current_play['away_score'])\n",
    "        features.append(score_diff)\n",
    "        features.append(home_score)\n",
    "        features.append(away_score)\n",
    "\n",
    "        # 2. Score differential trend (change over last few plays)\n",
    "        if len(prev_plays) >= 3:\n",
    "            score_diff_3plays_ago = self._safe_numeric_convert(prev_plays.iloc[-3]['score_diff'])\n",
    "            score_diff_trend = score_diff - score_diff_3plays_ago\n",
    "            features.append(score_diff_trend)\n",
    "        else:\n",
    "            features.append(0)\n",
    "\n",
    "        # 3. Time remaining (normalized by half)\n",
    "        time_remaining = self._safe_numeric_convert(current_play['time_remaining_half'])\n",
    "        features.append(time_remaining / 1200.0)  # 20 minutes per half\n",
    "\n",
    "        # 4. Half\n",
    "        features.append(self._safe_numeric_convert(current_play['half']))\n",
    "\n",
    "        # 5. Point spread (home_favored_by)\n",
    "        features.append(self._safe_numeric_convert(current_play['home_favored_by']))\n",
    "\n",
    "        # 6. Win probability (if available)\n",
    "        features.append(self._safe_numeric_convert(current_play['win_prob']))\n",
    "        features.append(self._safe_numeric_convert(current_play['naive_win_prob']))\n",
    "\n",
    "        # Momentum Features\n",
    "        # 7. Recent scoring runs\n",
    "        home_recent_points = 0\n",
    "        away_recent_points = 0\n",
    "        consecutive_home_points = 0\n",
    "        consecutive_away_points = 0\n",
    "\n",
    "        last_team = None\n",
    "\n",
    "        for i, play in prev_plays.iterrows():\n",
    "            if self._safe_numeric_convert(play['scoring_play']) == 1:\n",
    "                points = 0\n",
    "                if self._safe_numeric_convert(play['free_throw']) == 1:\n",
    "                    points = 1\n",
    "                elif self._safe_numeric_convert(play['three_pt']) == 1:\n",
    "                    points = 3\n",
    "                else:\n",
    "                    points = 2\n",
    "\n",
    "                if play['action_team'] == home_team:\n",
    "                    home_recent_points += points\n",
    "                    if last_team == home_team:\n",
    "                        consecutive_home_points += points\n",
    "                    else:\n",
    "                        consecutive_home_points = points\n",
    "                    consecutive_away_points = 0\n",
    "                    last_team = home_team\n",
    "                elif play['action_team'] == away_team:\n",
    "                    away_recent_points += points\n",
    "                    if last_team == away_team:\n",
    "                        consecutive_away_points += points\n",
    "                    else:\n",
    "                        consecutive_away_points = points\n",
    "                    consecutive_home_points = 0\n",
    "                    last_team = away_team\n",
    "\n",
    "        features.append(home_recent_points)\n",
    "        features.append(away_recent_points)\n",
    "        features.append(consecutive_home_points)\n",
    "        features.append(consecutive_away_points)\n",
    "\n",
    "        # 8. Which team has momentum currently\n",
    "        # Calculate momentum based on recent scoring\n",
    "        if consecutive_home_points > consecutive_away_points:\n",
    "            momentum_team = 1  # Home team has momentum\n",
    "        elif consecutive_away_points > consecutive_home_points:\n",
    "            momentum_team = -1  # Away team has momentum\n",
    "        else:\n",
    "            momentum_team = 0  # Neither team has clear momentum\n",
    "        features.append(momentum_team)\n",
    "\n",
    "        # 9. Recent scoring frequency and efficiency\n",
    "        home_scoring_plays = 0\n",
    "        away_scoring_plays = 0\n",
    "        home_shot_attempts = 0\n",
    "        away_shot_attempts = 0\n",
    "\n",
    "        for _, play in prev_plays.iterrows():\n",
    "            # Count scoring plays\n",
    "            if self._safe_numeric_convert(play['scoring_play']) == 1:\n",
    "                if play['action_team'] == home_team:\n",
    "                    home_scoring_plays += 1\n",
    "                elif play['action_team'] == away_team:\n",
    "                    away_scoring_plays += 1\n",
    "\n",
    "            # Count shot attempts\n",
    "            if play.get('shot_team') == home_team:\n",
    "                home_shot_attempts += 1\n",
    "            elif play.get('shot_team') == away_team:\n",
    "                away_shot_attempts += 1\n",
    "\n",
    "        features.append(home_scoring_plays / max(1, len(prev_plays)))\n",
    "        features.append(away_scoring_plays / max(1, len(prev_plays)))\n",
    "        features.append(home_scoring_plays / max(1, home_shot_attempts) if home_shot_attempts > 0 else 0)\n",
    "        features.append(away_scoring_plays / max(1, away_shot_attempts) if away_shot_attempts > 0 else 0)\n",
    "\n",
    "        # Shot Type Features\n",
    "        # 10. Recent three-point percentage\n",
    "        home_three_attempts = 0\n",
    "        home_three_makes = 0\n",
    "        away_three_attempts = 0\n",
    "        away_three_makes = 0\n",
    "\n",
    "        for _, play in prev_plays.iterrows():\n",
    "            if play.get('shot_team') == home_team and self._safe_numeric_convert(play['three_pt']) == 1:\n",
    "                home_three_attempts += 1\n",
    "                if play.get('shot_outcome') == 'made':\n",
    "                    home_three_makes += 1\n",
    "            elif play.get('shot_team') == away_team and self._safe_numeric_convert(play['three_pt']) == 1:\n",
    "                away_three_attempts += 1\n",
    "                if play.get('shot_outcome') == 'made':\n",
    "                    away_three_makes += 1\n",
    "\n",
    "        features.append(home_three_makes / max(1, home_three_attempts))\n",
    "        features.append(away_three_makes / max(1, away_three_attempts))\n",
    "\n",
    "        # 11. Recent free throw percentage\n",
    "        home_ft_attempts = 0\n",
    "        home_ft_makes = 0\n",
    "        away_ft_attempts = 0\n",
    "        away_ft_makes = 0\n",
    "\n",
    "        for _, play in prev_plays.iterrows():\n",
    "            if play.get('shot_team') == home_team and self._safe_numeric_convert(play['free_throw']) == 1:\n",
    "                home_ft_attempts += 1\n",
    "                if play.get('shot_outcome') == 'made':\n",
    "                    home_ft_makes += 1\n",
    "            elif play.get('shot_team') == away_team and self._safe_numeric_convert(play['free_throw']) == 1:\n",
    "                away_ft_attempts += 1\n",
    "                if play.get('shot_outcome') == 'made':\n",
    "                    away_ft_makes += 1\n",
    "\n",
    "        features.append(home_ft_makes / max(1, home_ft_attempts))\n",
    "        features.append(away_ft_makes / max(1, away_ft_attempts))\n",
    "\n",
    "        # 12. Recent two-point percentage\n",
    "        home_two_attempts = 0\n",
    "        home_two_makes = 0\n",
    "        away_two_attempts = 0\n",
    "        away_two_makes = 0\n",
    "\n",
    "        for _, play in prev_plays.iterrows():\n",
    "            if (play.get('shot_team') == home_team and\n",
    "                self._safe_numeric_convert(play['three_pt']) == 0 and\n",
    "                self._safe_numeric_convert(play['free_throw']) == 0):\n",
    "                home_two_attempts += 1\n",
    "                if play.get('shot_outcome') == 'made':\n",
    "                    home_two_makes += 1\n",
    "            elif (play.get('shot_team') == away_team and\n",
    "                  self._safe_numeric_convert(play['three_pt']) == 0 and\n",
    "                  self._safe_numeric_convert(play['free_throw']) == 0):\n",
    "                away_two_attempts += 1\n",
    "                if play.get('shot_outcome') == 'made':\n",
    "                    away_two_makes += 1\n",
    "\n",
    "        features.append(home_two_makes / max(1, home_two_attempts))\n",
    "        features.append(away_two_makes / max(1, away_two_attempts))\n",
    "\n",
    "        # Foul Features\n",
    "        # 13. Recent foul trouble\n",
    "        home_fouls = sum(1 for _, play in prev_plays.iterrows()\n",
    "                     if self._safe_numeric_convert(play['foul']) == 1\n",
    "                     and play['action_team'] == home_team)\n",
    "        away_fouls = sum(1 for _, play in prev_plays.iterrows()\n",
    "                     if self._safe_numeric_convert(play['foul']) == 1\n",
    "                     and play['action_team'] == away_team)\n",
    "\n",
    "        features.append(home_fouls)\n",
    "        features.append(away_fouls)\n",
    "\n",
    "        # Timeout Features\n",
    "        # 14. Timeout usage\n",
    "        features.append(self._safe_numeric_convert(current_play['home_time_out_remaining']))\n",
    "        features.append(self._safe_numeric_convert(current_play['away_time_out_remaining']))\n",
    "\n",
    "        # Current play type\n",
    "        # 15. Current play attributes\n",
    "        features.append(1 if self._safe_numeric_convert(current_play['scoring_play']) == 1 else 0)\n",
    "        features.append(1 if self._safe_numeric_convert(current_play['foul']) == 1 else 0)\n",
    "        features.append(1 if self._safe_numeric_convert(current_play['three_pt']) == 1 else 0)\n",
    "        features.append(1 if self._safe_numeric_convert(current_play['free_throw']) == 1 else 0)\n",
    "\n",
    "        # 16. Who has possession\n",
    "        features.append(1 if current_play.get('possession_before') == home_team else 0)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train the SVM model\"\"\"\n",
    "        # Calculate class weights based on distribution\n",
    "        if self.class_weight > 0:\n",
    "            pos_weight = torch.tensor(self.class_weight).to(device)\n",
    "        else:\n",
    "            pos_weight = torch.tensor(1.0).to(device)\n",
    "\n",
    "        # Initialize the model\n",
    "        self.model = SVM(self.input_dim).to(device)\n",
    "\n",
    "        # Define loss function with class weighting\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=self.reg_param)\n",
    "\n",
    "        # Create data loader for batch training\n",
    "        dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        data_loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.epochs):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for batch_X, batch_y in data_loader:\n",
    "                # Forward pass\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Print epoch statistics\n",
    "            avg_loss = running_loss/len(data_loader)\n",
    "\n",
    "            if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "                print(f'Epoch [{epoch+1}/{self.epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "                # Calculate and print current training metrics\n",
    "                if self.verbose and (epoch+1) % 30 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        train_outputs = self.model(X)\n",
    "                        train_predictions = (torch.sigmoid(train_outputs) >= 0.5).float()\n",
    "                        train_accuracy = (train_predictions == y).float().mean()\n",
    "                        print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "                        # Count predictions by class\n",
    "                        n_positive = train_predictions.sum().item()\n",
    "                        n_total = train_predictions.size(0)\n",
    "                        print(f'Predicting {n_positive} positive out of {n_total} ({n_positive/n_total*100:.2f}%)')\n",
    "\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        # Ensure X is properly formatted\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = self.scaler.transform(X)\n",
    "            X = torch.FloatTensor(X).to(device)\n",
    "\n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X)\n",
    "            predicted = torch.sigmoid(outputs)\n",
    "            predicted = (predicted >= 0.5).float()\n",
    "\n",
    "        return predicted.cpu().numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict probability estimates\"\"\"\n",
    "        # Ensure X is properly formatted\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = self.scaler.transform(X)\n",
    "            X = torch.FloatTensor(X).to(device)\n",
    "\n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Get probabilities\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "        return probs.cpu().numpy()\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"Evaluate the model\"\"\"\n",
    "        # Ensure inputs are properly formatted\n",
    "        if isinstance(X_test, np.ndarray):\n",
    "            X_test = self.scaler.transform(X_test)\n",
    "            X_test = torch.FloatTensor(X_test).to(device)\n",
    "\n",
    "        if isinstance(y_test, np.ndarray):\n",
    "            y_test = torch.FloatTensor(y_test).view(-1, 1).to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        # Convert to numpy for sklearn metrics\n",
    "        if isinstance(y_test, torch.Tensor):\n",
    "            y_test_np = y_test.cpu().numpy().flatten()\n",
    "        else:\n",
    "            y_test_np = y_test.flatten()\n",
    "\n",
    "        # Calculate metrics\n",
    "        conf_matrix = confusion_matrix(y_test_np, y_pred.flatten())\n",
    "        class_report = classification_report(y_test_np, y_pred.flatten(), output_dict=True)\n",
    "\n",
    "        return {\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'classification_report': class_report\n",
    "        }\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate the basketball momentum SVM model\"\"\"\n",
    "    # Load your CSV data\n",
    "    path = kagglehub.dataset_download(\"robbypeery/college-basketball-pbp-23-24\")\n",
    "    # csv = '/ALLTourneyPBP2324.csv'\n",
    "    csv = '/Colorado_pbp.csv'\n",
    "    print(\"Loading data...\")\n",
    "    data = pd.read_csv(path + csv)\n",
    "\n",
    "    print(\"Initializing model...\")\n",
    "    model = BasketballMomentumSVM(\n",
    "        num_previous_plays=5,\n",
    "        momentum_threshold=6,  # Using exactly 6 points as in your code\n",
    "        learning_rate=0.001,\n",
    "        epochs=150,\n",
    "        batch_size=64,\n",
    "        class_weight=10.0,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    print(\"Preparing data with momentum shift labels...\")\n",
    "    X, y, play_indices = model.prepare_data(data)\n",
    "\n",
    "    print(f\"Data shape: X = {X.shape}, y = {y.shape}\")\n",
    "\n",
    "    # Split into train and test sets\n",
    "    X_np = X.cpu().numpy()\n",
    "    y_np = y.cpu().numpy().flatten()\n",
    "    X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(X_np, y_np, test_size=0.2, random_state=42, stratify=y_np)\n",
    "\n",
    "    # Convert back to tensors\n",
    "    X_train = torch.FloatTensor(X_train_np).to(device)\n",
    "    y_train = torch.FloatTensor(y_train_np).view(-1, 1).to(device)\n",
    "    X_test = torch.FloatTensor(X_test_np).to(device)\n",
    "    y_test = torch.FloatTensor(y_test_np).view(-1, 1).to(device)\n",
    "\n",
    "    print(\"Training model to predict momentum shift starts...\")\n",
    "    model.train(X_train, y_train)\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    metrics = model.evaluate(X_test, y_test)\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(metrics['confusion_matrix'])\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, values in metrics['classification_report'].items():\n",
    "        if not isinstance(values, dict):\n",
    "            continue\n",
    "        print(f\"Class {label}:\")\n",
    "        print(f\"  Precision: {values['precision']:.3f}\")\n",
    "        print(f\"  Recall: {values['recall']:.3f}\")\n",
    "        print(f\"  F1-Score: {values['f1-score']:.3f}\")\n",
    "\n",
    "    print(\"\\nModel training complete!\")\n",
    "    print(\"This model now predicts whether a play will START a momentum shift!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "85d5146a713ed093",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data...\n",
      "Initializing model...\n",
      "Preparing data with momentum shift labels...\n",
      "Found 201 momentum shifts (runs of 6+ points)\n",
      "Total plays in runs: 2499\n",
      "Percentage of plays in runs: 23.02%\n",
      "Identified 201 momentum shift starting plays\n",
      "Percentage of momentum shift starts: 1.85%\n",
      "Total plays processed: 10688\n",
      "Momentum shift starts detected: 194 out of 10688 plays (1.82%)\n",
      "Class distribution: Counter({np.int64(0): 10494, np.int64(1): 194})\n",
      "Data shape: X = torch.Size([10688, 33]), y = torch.Size([10688, 1])\n",
      "Training model to predict momentum shift starts...\n",
      "Epoch [1/150], Loss: 0.5202\n",
      "Epoch [10/150], Loss: 0.2542\n",
      "Epoch [20/150], Loss: 0.2455\n",
      "Epoch [30/150], Loss: 0.2445\n",
      "Training Accuracy: 0.9497\n",
      "Predicting 469.0 positive out of 8550 (5.49%)\n",
      "Epoch [40/150], Loss: 0.2387\n",
      "Epoch [50/150], Loss: 0.2387\n",
      "Epoch [60/150], Loss: 0.2366\n",
      "Training Accuracy: 0.9309\n",
      "Predicting 662.0 positive out of 8550 (7.74%)\n",
      "Epoch [70/150], Loss: 0.2357\n",
      "Epoch [80/150], Loss: 0.2389\n",
      "Epoch [90/150], Loss: 0.2337\n",
      "Training Accuracy: 0.9280\n",
      "Predicting 699.0 positive out of 8550 (8.18%)\n",
      "Epoch [100/150], Loss: 0.2247\n",
      "Epoch [110/150], Loss: 0.2272\n",
      "Epoch [120/150], Loss: 0.2320\n",
      "Training Accuracy: 0.9430\n",
      "Predicting 560.0 positive out of 8550 (6.55%)\n",
      "Epoch [130/150], Loss: 0.2298\n",
      "Epoch [140/150], Loss: 0.2357\n",
      "Epoch [150/150], Loss: 0.2281\n",
      "Training Accuracy: 0.9538\n",
      "Predicting 448.0 positive out of 8550 (5.24%)\n",
      "Training complete!\n",
      "Evaluating model...\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2018   81]\n",
      " [  24   15]]\n",
      "\n",
      "Classification Report:\n",
      "Class 0.0:\n",
      "  Precision: 0.988\n",
      "  Recall: 0.961\n",
      "  F1-Score: 0.975\n",
      "Class 1.0:\n",
      "  Precision: 0.156\n",
      "  Recall: 0.385\n",
      "  F1-Score: 0.222\n",
      "Class macro avg:\n",
      "  Precision: 0.572\n",
      "  Recall: 0.673\n",
      "  F1-Score: 0.598\n",
      "Class weighted avg:\n",
      "  Precision: 0.973\n",
      "  Recall: 0.951\n",
      "  F1-Score: 0.961\n",
      "\n",
      "Model training complete!\n",
      "This model now predicts whether a play will START a momentum shift!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b83cbd70a65731be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
